{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### n_step_test_and_save\n",
    "nstep_pin18_20_test_and_save  \n",
    "<img src=\"assets/2023-07-27-13-29-30.png\" alt= “” width=\"500px\" >"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "python train.py --algos=nstep --self_play_episode_num=150 --result_dir=solutionsDRL_nstep_test_and_save  --load_ckpt=True --save_ckpt=True  --data_folder=\"test_data_/benchmark_reduced\" --wandbName=\"nstep_test_and_save\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## dtqn  (context_len==5 looks super good)\n",
    "dtqn need to pretain in order to filled it's buffer???"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### context_len_5  train and save  (problem all solved!!!)\n",
    "have already pretrained for 3 epoch in train_data (self_play 150)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "python train.py --algos=dtqn_per_noisy --self_play_episode_num=4 --load_ckpt=True --save_ckpt=True  --data_folder=\"train_data_/benchmark_reduced\" --wandbName=\"dtqn_per_noisy_context_len5_train\" --hid_layer=3 --emb_dim=64 --context_len=5 --early_stop=False  --enable_wandb=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "python train.py --algos=dtqn_per_noisy --self_play_episode_num=150 --result_dir=solutionsDRL --load_ckpt=True --save_ckpt=True  --data_folder=\"test_data_/benchmark_reduced\" --wandbName=\"dtqn_per_noisy_context_len5\" --hid_layer=3 --emb_dim=64 --context_len=5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I think sample from episode (_10_dtqn_per_noisy)     \n",
    "is better than sample from step (_11_dtqn_real_per)  \n",
    "    \n",
    "because our goal is to maximize the episode return, not step return\n",
    "(minize avg episode loss, not step loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### let's make a bench mark\n",
    "_12_ without per\n",
    "vs _10_  per\n",
    "we won't run _11_ because it is trash"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "python train.py --algos=dtqn_noisy --self_play_episode_num=4 --load_ckpt=True --save_ckpt=True  --data_folder=\"train_data_/benchmark_reduced\" --wandbName=\"NoPer\" --hid_layer=3 --emb_dim=64 --context_len=5 --early_stop=False  --enable_wandb=True\n",
    "# train 9  benchmarks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "python train.py --algos=dtqn_noisy --self_play_episode_num=150 --result_dir=solutionsDRL --load_ckpt=True --save_ckpt=False  --data_folder=\"test_data_/benchmark_reduced\" --wandbName=\"dtqn_noisy_pretain_test\" --hid_layer=3 --emb_dim=64 --context_len=5"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
